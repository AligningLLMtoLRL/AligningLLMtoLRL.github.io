{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7658007,"sourceType":"datasetVersion","datasetId":4465031}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Aya: Multilingual Instruction Following \n\nThe [Aya-101](https://huggingface.co/CohereForAI/aya-101) is a massively multilingual generative language model that follows instructions in 101 languages. Aya outperforms mT0 and BLOOMZ a wide variety of automatic and human evaluations despite covering double the number of languages. The Aya model is trained using [Aya Dataset](https://huggingface.co/datasets/CohereForAI/aya_dataset), [Aya Collection](https://huggingface.co/datasets/CohereForAI/aya_collection), [xP3x](https://huggingface.co/datasets/CohereForAI/xP3x), a subset of [DataProvenance collection](https://github.com/Data-Provenance-Initiative/Data-Provenance-Collection) and ShareGPT-Command. \n\n[Aya-101](https://huggingface.co/CohereForAI/aya-101) is based on 13 billion parameter [mT5](https://github.com/google-research/multilingual-t5) model and further instruction fine-tuned by [Cohere For AI](https://cohere.com/research). ","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://huggingface.co/CohereForAI/aya-101/resolve/main/aya-fig1.png\" width=\"1000\" height=\"600\"/>","metadata":{}},{"cell_type":"markdown","source":"*PS: This notebook is built on Kaggle using ***GPU T4x2*** accelerator and it is prepared based on https://github.com/philschmid/deep-learning-pytorch-huggingface/blob/main/training/flan-t5-samsum-summarization.ipynb and https://colab.research.google.com/drive/1VoYNfYDKcKRQRor98Zbf2-9VQTtGJ24k?usp=sharing*","metadata":{}},{"cell_type":"code","source":"!pip install transformers sentencepiece --upgrade\n!pip install datasets --upgrade\n!pip install ipywidgets torch\n!pip install evaluate rouge-score nltk","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install peft --upgrade\n!pip install accelerate bitsandbytes loralib --upgrade ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Task: Instruct Aya-101 to summarize Swahili content\n\nWe use [**\"XL-Sum: Large-Scale Multilingual Abstractive Summarization for 44 Languages\"**](https://aclanthology.org/2021.findings-acl.413/) to evaluate summarization performance in Swahili","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset \n\n# Only use the 10% of the test split for a fast demonstration of evaluation \nxlsum_swa_test = load_dataset(\"csebuetnlp/xlsum\", \"swahili\", split='test[:10%]')","metadata":{"execution":{"iopub.status.busy":"2024-02-21T11:59:25.278541Z","iopub.execute_input":"2024-02-21T11:59:25.278920Z","iopub.status.idle":"2024-02-21T11:59:31.222469Z","shell.execute_reply.started":"2024-02-21T11:59:25.278882Z","shell.execute_reply":"2024-02-21T11:59:31.221428Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/12.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23a7281669fa43dcad5861718381feb1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/1.59M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bac201c989e84480a5f15f5fadbad648"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/1.62M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12369f5766134e26b39b3627da7ec423"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/7898 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dcb8fa62d8f3498599434f890a92e1f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/987 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d8e99faed06451d8036085f2a02ecfa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/987 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b7e2e86a2484171be074dd78da2aa50"}},"metadata":{}}]},{"cell_type":"code","source":"swa_sample = xlsum_swa_test[1]\n\nprint(f\"Text: \\n{swa_sample['text']}\\n---------------\")\nprint(f\"Summary: \\n{swa_sample['summary']}\\n---------------\")","metadata":{"execution":{"iopub.status.busy":"2024-02-21T11:59:38.507644Z","iopub.execute_input":"2024-02-21T11:59:38.508055Z","iopub.status.idle":"2024-02-21T11:59:38.514335Z","shell.execute_reply.started":"2024-02-21T11:59:38.508019Z","shell.execute_reply":"2024-02-21T11:59:38.513375Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Text: \nTrump alijitetea kwenye mdahalo Jumapili kwa kumshambulia mumewe Hillary Clinton, Bill Clinton Spika wa Bunge la Wawakilishi Paul Ryan ameapa kuangazia sasa kuhakikisha wagombea wa chama hicho wanatetea viti vyao katika Bunge la Congress. Hata hivyo, hajabatilisha uamuzi wake wa kumuidhinisha mgombea huyo. Bw Trump naye amemjibu Bw Ryan kupitia mtandao wa Twitter na kusema hafai kupoteza wakati akimpigania. Awali, mpinzani wa Bw Trump kutoka chama cha Democratic Hillary Clinton ametilia shaka hatua ya Bw Trump kuomba radhi kutokana na matamshi hayo aliyoyatoa miaka 11 iliyopita. Kwenye kadha hiyo ya video, Bw Trump anaonekana akisema alivyoomba kushiriki mapenzi na mwanamke aliyeolewa. Aidha, anatoa matamshi ya kudhalilisha kuhusu wanawake. Lakini Jumapili, Bw Trump alisema maneno yake kwenye kanda hiyo ya video yalikuwa \"mazungumzo ya mzaha faraghani\". Hata hivyo alisema anajutia kuyasema. Akizungumza wakati wa mdahalo wa urais Jumapili, Bw Trump hata hivyo alisema hakumnyanyasa mwanamke yeyote kingono. Bi Clinton aliandika kwenye Twitter Jumatatu kwamba iwapo Bw Trump anasisitiza msimamo wake, bado inaonesha wazi kwamba \"hajajutia matamshi hayo\". Bw Paul Ryan akiwa kwenye kampeni Wisconsin Bw Trump alipoulizwa kuhusu kanda hiyo ya video kwenye mdahalo Jumapili, badala yake alimgeukia mpinzani wake Bi Clinton na kusema mumewe Bill Clinton alikuwa \"anawadhalilisha wanawake\" Bi Clinton alikataa kuzungumzia hilo. Takriban maafisa 38 wakuu wa chama cha Republican, wakiwemo masene, wabunge na magavana, wameondoa uungaji mkono wao kwa Bw Trump, tangu kutokea kwa ukanda huo wa video Ijumaa. Lakini Jumatatu, mwenyekiti wa Kamati ya Kitaifa ya Republian Reince Priebus alisema hakuna kitu chochote kimebadilika kuhusiana na kampeni. Bw Pence awali alisema matamshi ya Bw Trump \"hayawezi kutetewa\" Mgombea mwenza wa Bw Trump, Mike Pence, hata hivyo amesema ataendelea kumuunga mkono na kumtetea. Hata hivyo awali alikuwa amesema matamshi ya Bw Trump kwenye kanda hiyo ya video \"hayawezi kutetewa\". Lakini akiongea na CNN Jumatatu, bw Pence alisema \"ni heshima kubwa\" kwake kumuunga mkono Bw Trump na akakanusha madai kwamba alitafakari wazo wa kujiondoa. Donald Trump, kati, akiwa na wanawake ambao anadai walidhalilishwa na Bill Clinton na Hillary Clinton. Kutoka kulia: Paula Jones, Kathy Shelton, Juanita Broaddrick, na Kathleen Willey\n---------------\nSummary: \nAfisa mkuu zaidi wa chama cha Republican aliyechaguliwa amesema hatamtetea tena mgombea urais wa chama hicho Donald Trump, baada ya matamshi yake kuhusu wanawake ambayo yamezua utata.\n---------------\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# [Aya Model: An Instruction Finetuned Open-Access Multilingual Language Model](https://arxiv.org/abs/2402.07827)","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\n# Load Aya collection\naya_collection = load_dataset(\"CohereForAI/aya_collection\", \"translated_wikiqa\")\nprint(aya_collection)\n\n# List of languages\nlanguages = sorted(set(aya_collection[\"train\"][\"language\"]))\nprint(f'Number of languages in Aya collection, translated_dolly subset: {len(languages)}\\n')\nprint(f'Languages in Aya collection, translated_dolly subset: {languages}\\n')","metadata":{"execution":{"iopub.status.busy":"2024-02-21T11:59:41.725346Z","iopub.execute_input":"2024-02-21T11:59:41.726214Z","iopub.status.idle":"2024-02-21T11:59:52.015570Z","shell.execute_reply.started":"2024-02-21T11:59:41.726178Z","shell.execute_reply":"2024-02-21T11:59:52.014687Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/71.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5a1a0fd203c4a7387fe500e836c1482"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/6.46M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1647ac5238304c8fb8f4b9aaaaa9569d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/23.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a8100d2e9c345069d3e953d76329d52"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/3.25M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a153e7c33494b4baf0a6b56dde10257"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/34867 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"883ee7fe63d84125a63e1a19f2c57208"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/123760 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3bde40c34d344a94be10797bc7f15b61"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/16660 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c9978ce55d549ed86645706b1258e51"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    test: Dataset({\n        features: ['id', 'inputs', 'targets', 'dataset_name', 'sub_dataset_name', 'task_type', 'template_id', 'language', 'script', 'split'],\n        num_rows: 34867\n    })\n    train: Dataset({\n        features: ['id', 'inputs', 'targets', 'dataset_name', 'sub_dataset_name', 'task_type', 'template_id', 'language', 'script', 'split'],\n        num_rows: 123760\n    })\n    validation: Dataset({\n        features: ['id', 'inputs', 'targets', 'dataset_name', 'sub_dataset_name', 'task_type', 'template_id', 'language', 'script', 'split'],\n        num_rows: 16660\n    })\n})\nNumber of languages in Aya collection, translated_dolly subset: 113\n\nLanguages in Aya collection, translated_dolly subset: ['ace', 'acm', 'acq', 'aeb', 'afr', 'ajp', 'als', 'amh', 'apc', 'arb', 'ars', 'ary', 'arz', 'azb', 'azj', 'bel', 'ben', 'bjn', 'bul', 'cat', 'ceb', 'ces', 'ckb', 'cym', 'dan', 'deu', 'ell', 'eng', 'epo', 'est', 'eus', 'fin', 'fra', 'gla', 'gle', 'glg', 'guj', 'hat', 'hau', 'heb', 'hin', 'hun', 'hye', 'ibo', 'ind', 'isl', 'ita', 'jav', 'jpn', 'kan', 'kas', 'kat', 'kaz', 'khk', 'khm', 'kir', 'kmr', 'knc', 'kor', 'lao', 'lit', 'ltz', 'lvs', 'mal', 'mar', 'min', 'mkd', 'mlt', 'mni', 'mri', 'mya', 'nld', 'nno', 'nob', 'npi', 'nso', 'pbt', 'pes', 'plt', 'pol', 'por', 'ron', 'rus', 'sin', 'slk', 'slv', 'smo', 'sna', 'snd', 'som', 'sot', 'spa', 'srp', 'sun', 'swe', 'swh', 'tam', 'taq', 'tel', 'tgk', 'tha', 'tur', 'ukr', 'urd', 'uzn', 'vie', 'xho', 'ydd', 'yor', 'yue', 'zho', 'zsm', 'zul']\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load Aya dataset\naya_dataset = load_dataset(\"CohereForAI/aya_dataset\")\nprint(aya_dataset)\n\n# List of languages\nlanguages = sorted(set(aya_dataset[\"train\"][\"language_code\"]))\nprint(f'Number of languages in Aya dataset: {len(languages)}\\n')\nprint(f'Languages in Aya dataset: {languages}\\n')\n\n# Annotation type in the dataset\nannotation_type = sorted(set(aya_dataset[\"train\"][\"annotation_type\"]))\nprint(f'Annotation types in Aya dataset: {annotation_type}')","metadata":{"execution":{"iopub.status.busy":"2024-02-21T12:00:04.012553Z","iopub.execute_input":"2024-02-21T12:00:04.013323Z","iopub.status.idle":"2024-02-21T12:00:13.914197Z","shell.execute_reply.started":"2024-02-21T12:00:04.013289Z","shell.execute_reply":"2024-02-21T12:00:13.913274Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/13.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"223b744b7fc649319d77345f32d9c561"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/137M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ce57933b78b47a699afb2924e7a7727"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/978k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d4d606a585c498fad2fa4b37f8940a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/202364 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4561e510564b4f389a844aeb57125351"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1750 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6fe890f409a945be9d3a48281188a864"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['inputs', 'targets', 'language', 'language_code', 'annotation_type', 'user_id'],\n        num_rows: 202364\n    })\n    test: Dataset({\n        features: ['inputs', 'targets', 'language', 'language_code', 'annotation_type', 'user_id'],\n        num_rows: 1750\n    })\n})\nNumber of languages in Aya dataset: 70\n\nLanguages in Aya dataset: ['acq', 'ajp', 'als', 'amh', 'arb', 'ars', 'ary', 'arz', 'ben', 'ceb', 'ckb', 'dan', 'deu', 'ell', 'eng', 'eus', 'fil', 'fin', 'fra', 'gle', 'guj', 'hat', 'hau', 'hin', 'hun', 'ibo', 'ind', 'ita', 'jav', 'jpn', 'kan', 'kir', 'kor', 'lit', 'mal', 'mar', 'mya', 'nld', 'npi', 'nso', 'nya', 'pan', 'pbt', 'pes', 'plt', 'pol', 'por', 'rus', 'sin', 'sna', 'snd', 'som', 'spa', 'srp', 'sun', 'swe', 'swh', 'tam', 'tel', 'tha', 'tur', 'ukr', 'urd', 'vie', 'wol', 'xho', 'yor', 'zho', 'zsm', 'zul']\n\nAnnotation types in Aya dataset: ['original-annotations', 're-annotations']\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForSeq2SeqLM\nfrom transformers import logging as hf_logging\n\naya = AutoModelForSeq2SeqLM.from_pretrained(\"CohereForAI/aya-101\", torch_dtype=torch.bfloat16, device_map='auto')","metadata":{"execution":{"iopub.status.busy":"2024-02-20T15:10:46.397402Z","iopub.status.idle":"2024-02-20T15:10:46.397876Z","shell.execute_reply.started":"2024-02-20T15:10:46.397625Z","shell.execute_reply":"2024-02-20T15:10:46.397653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\nmodel_id = \"CohereForAI/aya-101\"\ntokenizer = AutoTokenizer.from_pretrained(model_id)","metadata":{"execution":{"iopub.status.busy":"2024-02-21T12:00:16.208601Z","iopub.execute_input":"2024-02-21T12:00:16.208994Z","iopub.status.idle":"2024-02-21T12:00:19.523501Z","shell.execute_reply.started":"2024-02-21T12:00:16.208960Z","shell.execute_reply":"2024-02-21T12:00:19.522452Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Swahili example\nswa_text = swa_sample[\"text\"]\nprompt = f\"Summarize the following text:\\n{swa_text}\"\ninputs = tokenizer(prompt, max_length=256, return_tensors=\"pt\").to(\"cuda\")\noutput = aya.generate(**inputs, do_sample=False, max_new_tokens=64)\noutput = tokenizer.batch_decode(output, skip_special_tokens=True)\nprint(f\"Text: \\n{prompt}\\n---------------\")\nprint(f\"Summary: \\n{output}\\n---------------\")","metadata":{"execution":{"iopub.status.busy":"2024-02-20T15:11:34.931574Z","iopub.execute_input":"2024-02-20T15:11:34.932279Z","iopub.status.idle":"2024-02-20T15:11:40.365791Z","shell.execute_reply.started":"2024-02-20T15:11:34.932246Z","shell.execute_reply":"2024-02-20T15:11:40.364782Z"},"trusted":true},"execution_count":75,"outputs":[{"name":"stdout","text":"Text: \nSummarize the following text:\nTrump alijitetea kwenye mdahalo Jumapili kwa kumshambulia mumewe Hillary Clinton, Bill Clinton Spika wa Bunge la Wawakilishi Paul Ryan ameapa kuangazia sasa kuhakikisha wagombea wa chama hicho wanatetea viti vyao katika Bunge la Congress. Hata hivyo, hajabatilisha uamuzi wake wa kumuidhinisha mgombea huyo. Bw Trump naye amemjibu Bw Ryan kupitia mtandao wa Twitter na kusema hafai kupoteza wakati akimpigania. Awali, mpinzani wa Bw Trump kutoka chama cha Democratic Hillary Clinton ametilia shaka hatua ya Bw Trump kuomba radhi kutokana na matamshi hayo aliyoyatoa miaka 11 iliyopita. Kwenye kadha hiyo ya video, Bw Trump anaonekana akisema alivyoomba kushiriki mapenzi na mwanamke aliyeolewa. Aidha, anatoa matamshi ya kudhalilisha kuhusu wanawake. Lakini Jumapili, Bw Trump alisema maneno yake kwenye kanda hiyo ya video yalikuwa \"mazungumzo ya mzaha faraghani\". Hata hivyo alisema anajutia kuyasema. Akizungumza wakati wa mdahalo wa urais Jumapili, Bw Trump hata hivyo alisema hakumnyanyasa mwanamke yeyote kingono. Bi Clinton aliandika kwenye Twitter Jumatatu kwamba iwapo Bw Trump anasisitiza msimamo wake, bado inaonesha wazi kwamba \"hajajutia matamshi hayo\". Bw Paul Ryan akiwa kwenye kampeni Wisconsin Bw Trump alipoulizwa kuhusu kanda hiyo ya video kwenye mdahalo Jumapili, badala yake alimgeukia mpinzani wake Bi Clinton na kusema mumewe Bill Clinton alikuwa \"anawadhalilisha wanawake\" Bi Clinton alikataa kuzungumzia hilo. Takriban maafisa 38 wakuu wa chama cha Republican, wakiwemo masene, wabunge na magavana, wameondoa uungaji mkono wao kwa Bw Trump, tangu kutokea kwa ukanda huo wa video Ijumaa. Lakini Jumatatu, mwenyekiti wa Kamati ya Kitaifa ya Republian Reince Priebus alisema hakuna kitu chochote kimebadilika kuhusiana na kampeni. Bw Pence awali alisema matamshi ya Bw Trump \"hayawezi kutetewa\" Mgombea mwenza wa Bw Trump, Mike Pence, hata hivyo amesema ataendelea kumuunga mkono na kumtetea. Hata hivyo awali alikuwa amesema matamshi ya Bw Trump kwenye kanda hiyo ya video \"hayawezi kutetewa\". Lakini akiongea na CNN Jumatatu, bw Pence alisema \"ni heshima kubwa\" kwake kumuunga mkono Bw Trump na akakanusha madai kwamba alitafakari wazo wa kujiondoa. Donald Trump, kati, akiwa na wanawake ambao anadai walidhalilishwa na Bill Clinton na Hillary Clinton. Kutoka kulia: Paula Jones, Kathy Shelton, Juanita Broaddrick, na Kathleen Willey\n---------------\nSummary: \n['Mwenyekiti wa chama cha Republican nchini Marekani Donald Trump ameahidi kufanya kazi na chama hicho kuhakikisha chama hicho kinashinda uchaguzi mkuu wa chama hicho.']\n---------------\n","output_type":"stream"}]},{"cell_type":"code","source":"max_input_len = 256\nmax_target_len = 64\n\ndef preprocess_xlsum(examples, padding=\"max_length\"):\n    inputs = [f'Summarize the follow text:\\n{text}' for text in examples[\"text\"]]\n    \n     # tokenize inputs\n    model_inputs = tokenizer(inputs, max_length=max_input_len, padding=padding, truncation=True)\n\n    # Tokenize targets with the `text_target` keyword argument\n    labels = tokenizer(text_target=examples[\"summary\"], max_length=max_target_len, padding=padding, truncation=True)\n    \n    # If we are padding here, replace all tokenizer.pad_token_id in the labels by -100 when we want to ignore\n    # padding in the loss.\n    if padding == \"max_length\":\n        labels[\"input_ids\"] = [\n            [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n        ]\n\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\n\ntokenized_xlsum_swahili_test = xlsum_swa_test.map(preprocess_xlsum, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-21T12:00:26.348103Z","iopub.execute_input":"2024-02-21T12:00:26.349453Z","iopub.status.idle":"2024-02-21T12:00:26.692082Z","shell.execute_reply.started":"2024-02-21T12:00:26.349399Z","shell.execute_reply":"2024-02-21T12:00:26.691106Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/99 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6549a93fed64b86b2d9253cad816b87"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\n\n# we want to ignore tokenizer pad token in the loss\nlabel_pad_token_id = -100\n# Data collator\ndata_collator = DataCollatorForSeq2Seq(\n    tokenizer,\n    model=aya,\n    label_pad_token_id=label_pad_token_id, # tokenizer.pad_token_id,\n    pad_to_multiple_of=8\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import evaluate\nimport nltk\nimport numpy as np\nfrom nltk.tokenize import sent_tokenize\nnltk.download(\"punkt\")\n\n# Metric\nmetric = evaluate.load(\"rouge\")\n\n# helper function to postprocess text\ndef postprocess_text(preds, labels):\n    preds = [pred.strip() for pred in preds]\n    labels = [label.strip() for label in labels]\n\n    # rougeLSum expects newline after each sentence\n    preds = [\"\\n\".join(sent_tokenize(pred)) for pred in preds]\n    labels = [\"\\n\".join(sent_tokenize(label)) for label in labels]\n\n    return preds, labels\n\ndef compute_metrics(eval_preds):\n    preds, labels = eval_preds\n    if isinstance(preds, tuple):\n        preds = preds[0]\n    preds = np.where(preds != -100, preds, tokenizer.pad_token_id)\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n    # Replace -100 in the labels as we can't decode them.\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    # Some simple post-processing\n    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n\n    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n    result = {k: round(v * 100, 4) for k, v in result.items()}\n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n    result[\"gen_len\"] = np.mean(prediction_lens)\n    return result","metadata":{"execution":{"iopub.status.busy":"2024-02-21T12:00:30.661428Z","iopub.execute_input":"2024-02-21T12:00:30.662407Z","iopub.status.idle":"2024-02-21T12:00:45.799315Z","shell.execute_reply.started":"2024-02-21T12:00:30.662353Z","shell.execute_reply":"2024-02-21T12:00:45.798273Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"2024-02-21 12:00:32.548458: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-21 12:00:32.548590: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-21 12:00:32.690888: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"476cb4942812433d9f9417c68131e6e6"}},"metadata":{}}]},{"cell_type":"code","source":"from huggingface_hub import HfFolder\nfrom transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n\ntrain_batch_size = 0\neval_batch_size = 1\n\n# Create Trainer instance\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=Seq2SeqTrainingArguments(\n        output_dir=model_id,\n        do_train=False,\n        per_device_eval_batch_size=eval_batch_size,\n        predict_with_generate=True,\n        generation_max_length=max_target_len,\n        report_to=\"none\",\n        push_to_hub=False,\n    ),\n    data_collator=data_collator,\n    train_dataset=tokenized_dolly_english['train'],\n    eval_dataset=tokenized_xlsum_swa_test,\n    compute_metrics=compute_metrics,\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-20T15:32:00.137580Z","iopub.execute_input":"2024-02-20T15:32:00.137924Z","iopub.status.idle":"2024-02-20T15:32:00.154229Z","shell.execute_reply.started":"2024-02-20T15:32:00.137897Z","shell.execute_reply":"2024-02-20T15:32:00.153316Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"trainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2024-02-20T15:32:03.795557Z","iopub.execute_input":"2024-02-20T15:32:03.796325Z","iopub.status.idle":"2024-02-20T15:33:11.269958Z","shell.execute_reply.started":"2024-02-20T15:32:03.796283Z","shell.execute_reply":"2024-02-20T15:33:11.269051Z"},"trusted":true},"execution_count":117,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [10/10 01:01]\n    </div>\n    "},"metadata":{}},{"execution_count":117,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 1.3297851085662842,\n 'eval_rouge1': 35.1247,\n 'eval_rouge2': 14.4541,\n 'eval_rougeL': 27.442,\n 'eval_rougeLsum': 27.7463,\n 'eval_gen_len': 40.3,\n 'eval_runtime': 67.4628,\n 'eval_samples_per_second': 0.148,\n 'eval_steps_per_second': 0.148}"},"metadata":{}}]},{"cell_type":"code","source":"import torch\n\n# Free memory for the second training \ndel model\ndel trainer_en\ntorch.cuda.empty_cache()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Our Swahili instruction dataset\n# This dataset is translated from Dolly-15k English instructions, later filtered and post-edited by Toloka\n!wget https://github.com/AligningLLMtoLRL/AligningLLMtoLRL.github.io/raw/main/materials/Dataset.zip\n!unzip Dataset.zip","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\ndolly_swahili_df = pd.read_excel(\"/kaggle/working/translated_ds.xlsx\")\ndolly_swahili_df.head(2)","metadata":{"execution":{"iopub.status.busy":"2024-02-21T14:08:28.938776Z","iopub.execute_input":"2024-02-21T14:08:28.939499Z","iopub.status.idle":"2024-02-21T14:08:33.113641Z","shell.execute_reply.started":"2024-02-21T14:08:28.939459Z","shell.execute_reply":"2024-02-21T14:08:33.112628Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"                                task_id  \\\n0  000287b55d--656f562fa7ccfa2fa62cbad5   \n1  000287b55d--656f562fa7ccfa2fa62cbb0b   \n\n                                    INPUT:context_tr  \\\n0   \"I'm So Excited\" ni wimbo wa mwimbaji wa Aust...   \n1                                                      \n\n                                   INPUT:context_src  \\\n0  \"I'm So Excited\" is a song by Australian singe...   \n1                                                      \n\n                                   INPUT:response_tr  \\\n0  \"I'm So Excited\" ni wimbo wa mwimbaji wa Austr...   \n1  Kupanga safari ya kwenda Ulaya ni sawa na kupa...   \n\n                                  INPUT:response_src  \\\n0  \"I'm So Excited\" is a song by Australian singe...   \n1  Planning a trip to Europe is similar to planni...   \n\n                                INPUT:instruction_tr  \\\n0       Ni nani mwimbaji wa wimbo wa I'm So Excited?   \n1   Je, nifanyeje kuhusu kupanga safari ya kwenda...   \n\n                              INPUT:instruction_src  toloka probabilities  \n0     Who is the singer of the song I'm So Excited?              0.988446  \n1  How should I go about planning a trip to Europe?              0.982769  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>task_id</th>\n      <th>INPUT:context_tr</th>\n      <th>INPUT:context_src</th>\n      <th>INPUT:response_tr</th>\n      <th>INPUT:response_src</th>\n      <th>INPUT:instruction_tr</th>\n      <th>INPUT:instruction_src</th>\n      <th>toloka probabilities</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000287b55d--656f562fa7ccfa2fa62cbad5</td>\n      <td>\"I'm So Excited\" ni wimbo wa mwimbaji wa Aust...</td>\n      <td>\"I'm So Excited\" is a song by Australian singe...</td>\n      <td>\"I'm So Excited\" ni wimbo wa mwimbaji wa Austr...</td>\n      <td>\"I'm So Excited\" is a song by Australian singe...</td>\n      <td>Ni nani mwimbaji wa wimbo wa I'm So Excited?</td>\n      <td>Who is the singer of the song I'm So Excited?</td>\n      <td>0.988446</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000287b55d--656f562fa7ccfa2fa62cbb0b</td>\n      <td></td>\n      <td></td>\n      <td>Kupanga safari ya kwenda Ulaya ni sawa na kupa...</td>\n      <td>Planning a trip to Europe is similar to planni...</td>\n      <td>Je, nifanyeje kuhusu kupanga safari ya kwenda...</td>\n      <td>How should I go about planning a trip to Europe?</td>\n      <td>0.982769</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from datasets import Dataset\n\n# Load our Swahili instruction dataset\ndolly_swahili = Dataset.from_pandas(dolly_swahili_df)\n\ndef preprocess_dolly(examples, padding=\"max_length\"):\n    inputs = []\n    targets = []\n    for instruction, context in zip(examples[\"INPUT:instruction_tr\"], examples[\"INPUT:context_tr\"]):\n        if len(context) > 0:\n          inputs.append(f'{instruction}\\nContext: {context}')\n        else:\n          inputs.append(instruction)\n    \n    # tokenize inputs\n    model_inputs = tokenizer(inputs, max_length=max_input_len, padding=padding, truncation=True)\n\n    # Tokenize targets with the `text_target` keyword argument\n    labels = tokenizer(text_target=examples[\"INPUT:response_tr\"], max_length=max_target_len, padding=padding, truncation=True)\n    \n    # If we are padding here, replace all tokenizer.pad_token_id in the labels by -100 when we want to ignore\n    # padding in the loss.\n    if padding == \"max_length\":\n        labels[\"input_ids\"] = [\n            [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n        ]\n\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\n\n# Preprocess the dataset\ntokenized_dolly_swahili = dolly_swahili.map(preprocess_dolly, batched=True, \n                                            remove_columns=[\"INPUT:context_src\", \"INPUT:instruction_src\", \"INPUT:response_src\", \"toloka probabilities\", \"task_id\"])","metadata":{"execution":{"iopub.status.busy":"2024-02-21T12:23:51.915164Z","iopub.execute_input":"2024-02-21T12:23:51.915657Z","iopub.status.idle":"2024-02-21T12:24:00.003022Z","shell.execute_reply.started":"2024-02-21T12:23:51.915612Z","shell.execute_reply":"2024-02-21T12:24:00.002061Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/12125 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, BitsAndBytesConfig\nimport torch\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16\n)\n\n# load model from the hub\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_id, quantization_config=bnb_config, device_map=\"auto\")","metadata":{"execution":{"iopub.status.busy":"2024-02-21T12:25:29.213600Z","iopub.execute_input":"2024-02-21T12:25:29.213921Z","iopub.status.idle":"2024-02-21T12:32:54.424298Z","shell.execute_reply.started":"2024-02-21T12:25:29.213894Z","shell.execute_reply":"2024-02-21T12:32:54.423185Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/836 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a43bf34b2414558a7ecf412a331ffd4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc4b2d4e3e1743b99916824a1eab5a89"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/11 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2cb1b261ff14f569a3146d70157decd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00011.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0ca0ac72ec24274a4f849360a1008cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00011.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"108f8a47dc9841cb941db79d432208fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00011.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b440dbe3c1d49338e81c4f00673c915"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00011.safetensors:   0%|          | 0.00/4.90G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53e9cdbd21e744e8bdd12e9b7b0955fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00005-of-00011.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db71543180dc4abbb9c6cb89cda383d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00006-of-00011.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89b96229d01b4e7ab73e084c573e87ec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00007-of-00011.safetensors:   0%|          | 0.00/4.87G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5752be72f7ae426c9884d2b03370017b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00008-of-00011.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a62cb202c7d6461a9c2f3cbe1771acc6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00009-of-00011.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39cff7fed3154d67b3ce4f9e7fa48443"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00010-of-00011.safetensors:   0%|          | 0.00/2.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42d0c7d7e406467d8889d135332f5c2c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00011-of-00011.safetensors:   0%|          | 0.00/4.10G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d5188b6a4294fa88d80840904d1063a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/11 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e28eb7521eb4f3fb2d698cab661d693"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/142 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69affb449c214ad0801ac232cf455677"}},"metadata":{}}]},{"cell_type":"code","source":"from peft import prepare_model_for_kbit_training\n\nmodel.gradient_checkpointing_enable()\nmodel = prepare_model_for_kbit_training(model)","metadata":{"execution":{"iopub.status.busy":"2024-02-21T12:33:39.697651Z","iopub.execute_input":"2024-02-21T12:33:39.698064Z","iopub.status.idle":"2024-02-21T12:33:39.809082Z","shell.execute_reply.started":"2024-02-21T12:33:39.698030Z","shell.execute_reply":"2024-02-21T12:33:39.808327Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model\n\nconfig = LoraConfig(\n    r=8, \n    lora_alpha=32, \n    target_modules=[\"k\", \"q\", \"v\"],\n    lora_dropout=0.05, \n    bias=\"none\", \n    task_type=\"TaskType.SEQ_2_SEQ_LM\"\n)\n\nmodel = get_peft_model(model, config)","metadata":{"execution":{"iopub.status.busy":"2024-02-21T12:33:42.314064Z","iopub.execute_input":"2024-02-21T12:33:42.314919Z","iopub.status.idle":"2024-02-21T12:33:42.780254Z","shell.execute_reply.started":"2024-02-21T12:33:42.314885Z","shell.execute_reply":"2024-02-21T12:33:42.779454Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\n\n# we want to ignore tokenizer pad token in the loss\nlabel_pad_token_id = -100\n# Data collator\ndata_collator = DataCollatorForSeq2Seq(\n    tokenizer,\n    model=model,\n    label_pad_token_id=label_pad_token_id,\n    pad_to_multiple_of=8\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-21T12:34:06.448352Z","iopub.execute_input":"2024-02-21T12:34:06.449015Z","iopub.status.idle":"2024-02-21T12:34:06.454050Z","shell.execute_reply.started":"2024-02-21T12:34:06.448975Z","shell.execute_reply":"2024-02-21T12:34:06.453089Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import HfFolder\nfrom transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n\ntrain_batch_size = 2\neval_batch_size = 1\n\n# Hugging Face repository id\nnew_aya_id = f\"aya-swa-dolly-qlora\"\n\n# Create Trainer instance\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=Seq2SeqTrainingArguments(\n        output_dir=new_aya_id,\n        per_device_train_batch_size=train_batch_size,\n        per_device_eval_batch_size=eval_batch_size,\n        gradient_accumulation_steps=4,\n        predict_with_generate=True,\n        learning_rate=1e-4,\n        max_steps=200,\n        # logging & evaluation strategies\n        logging_strategy=\"steps\",\n        logging_steps=50,\n        evaluation_strategy=\"no\",\n        save_strategy=\"no\",\n        load_best_model_at_end=True,\n        generation_max_length=max_target_len,\n        report_to=\"none\",\n        push_to_hub=False,\n        optim=\"paged_adamw_8bit\"\n    ),\n    data_collator=data_collator,\n    train_dataset=tokenized_dolly_swahili,\n    eval_dataset=tokenized_xlsum_swahili_test,\n    compute_metrics=compute_metrics,\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-21T12:48:52.762434Z","iopub.execute_input":"2024-02-21T12:48:52.763186Z","iopub.status.idle":"2024-02-21T12:48:52.774599Z","shell.execute_reply.started":"2024-02-21T12:48:52.763149Z","shell.execute_reply":"2024-02-21T12:48:52.773766Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# Fine-tune the model\ntrainer.train()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the fine-tuned model\ntrainer.evaluate()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"```json\n{'eval_loss': 1.3190653324127197,\n 'eval_rouge1': 38.0103,\n 'eval_rouge2': 15.7488,\n 'eval_rougeL': 28.7387,\n 'eval_rougeLsum': 28.7794,\n 'eval_gen_len': 37.9,\n 'eval_runtime': 88.4342,\n 'eval_samples_per_second': 0.113,\n 'eval_steps_per_second': 0.113}\n```","metadata":{}},{"cell_type":"code","source":"# Save model and tokenizer\ntrainer.model.save_pretrained(repository_id)\ntokenizer.save_pretrained(repository_id)","metadata":{},"execution_count":null,"outputs":[]}]}